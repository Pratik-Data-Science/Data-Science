{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1b4fc5",
   "metadata": {},
   "source": [
    "### Advanced Pandas - Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52258103",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b9fbb",
   "metadata": {},
   "source": [
    "##### What is multiindex object?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c4379",
   "metadata": {},
   "source": [
    "In pandas, a MultiIndex object is a way of representing index or column levels as a hierarchy. It allows you to have multiple levels of row or column labels in a DataFrame, providing a way to work with higher dimensional data while maintaining the structure and ease of use that pandas offers.\n",
    "\n",
    "This can be particularly useful when dealing with complex, structured datasets where data is naturally organized into multiple levels of categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869984b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0305a",
   "metadata": {},
   "source": [
    "##### What is multiindex series?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498c108",
   "metadata": {},
   "source": [
    "A multiIndex Series in pandas is a one-dimensional labeled array capable of storing data with multiple levels of index. It allows you to have more than one index per row, which can be useful for handling complex and hierarchical data. This can be particularly helpful when working with datasets that have multiple dimensions or levels of categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03df38a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd3425",
   "metadata": {},
   "source": [
    "##### What is unstack in pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e6ab2",
   "metadata": {},
   "source": [
    "In pandas, the unstack method is used to pivot a level of the (multi-level) index labels. It effectively \"rotates\" the innermost level of a multi-level index to become the innermost level of the columns, producing a reshaped DataFrame.\n",
    "This can be helpful when you have hierarchical row index labels and you want to move one of these levels to become column labels, making the data more accessible for analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465cc4b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8c570",
   "metadata": {},
   "source": [
    "##### What is stack in pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363b122",
   "metadata": {},
   "source": [
    "In pandas, the stack method is used to pivot the innermost level of the column labels to become the innermost level of the row index. This effectively \"rotates\" the innermost level of the columns to become the innermost level of the index, reshaping the DataFrame.\n",
    "\n",
    "Stacking is particularly useful when you want to move the innermost level of column labels to become a new innermost level of row labels, which can be helpful for certain types of data manipulation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d402",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962827e4",
   "metadata": {},
   "source": [
    "##### Why is multiindex series required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ffb5e",
   "metadata": {},
   "source": [
    "MultiIndex Series are required in pandas for situations where you need to work with higher dimensional data or when you need to represent and manipulate data with multiple levels of indexing. This is particularly useful when dealing with complex datasets that require hierarchical indexing, such as panel data or data with multiple categories and subcategories.\n",
    "MultiIndex Series allow for more intricate and detailed indexing and grouping, making it easier to perform operations and analysis on structured, multi-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f3800",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853f7e7",
   "metadata": {},
   "source": [
    "##### What is multiindex dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e29d0",
   "metadata": {},
   "source": [
    "A MultiIndex DataFrame in pandas is a DataFrame with multiple levels of indexing for both rows and columns. This means that the rows and columns have hierarchical index levels, allowing for more complex and structured representation of the data.\n",
    "MultiIndex DataFrames are particularly useful when dealing with multi-dimensional datasets where data needs to be organized and analyzed based on multiple categorical or hierarchical criteria. They enable more advanced operations such as grouping, slicing, and aggregating data across different levels of the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcaa04",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18fa99",
   "metadata": {},
   "source": [
    "##### What is long and wide data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd98b9",
   "metadata": {},
   "source": [
    "Long and wide data are terms used to describe different formats of data organization, often encountered in the context of databases and spreadsheets.\n",
    "\n",
    "Wide data, also known as \"pivoted\" data, typically has a wide format where each variable is in a separate column, making it easier to read for humans but sometimes harder to work with for analysis.\n",
    "\n",
    "Long data, also known as \"stacked\" or \"molten\" data, usually has a tall format where each row represents a single observation and each variable has its own column, making it easier for analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c614527",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea24807",
   "metadata": {},
   "source": [
    "##### What is pivot table in pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56214fb",
   "metadata": {},
   "source": [
    "In pandas, a pivot table is a way to summarize and aggregate data in a DataFrame. It allows you to restructure and group data, providing a new perspective for analysis. By specifying rows, columns, and values, you can reshape the data and compute aggregations like sums, averages, or counts.\n",
    "\n",
    "In simple words, the pivot table takes simple column-wise data as input and group the entries into a two-dimensional table that provides a multidimensional summarization of the data\n",
    "\n",
    "Pivot tables are a powerful tool for data analysis and are commonly used to gain insights from complex datasets. If you need help with specific pivot table operations or anything else related to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca33479",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350f018",
   "metadata": {},
   "source": [
    "##### What are the steps while working on textual data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958be19",
   "metadata": {},
   "source": [
    "When working with textual data, there are several common steps to consider:\n",
    "\n",
    "<b>1. Data Acquisition/Gathering:</b> Obtain the textual data from various sources such as databases, APIs, or text files.<br>\n",
    "<b>2. Data Cleaning:</b> Cleaning the data as ML follows the principle of garbage in garbage out.<br>\n",
    "<b>3. Data Preprocessing:</b> This involves cleaning the data by removing irrelevant characters, punctuation, and formatting inconsistencies. It may also include tasks like tokenization, stemming, and lemmatization to normalize the text.<br>\n",
    "<b>4. Feature Extraction:</b> Convert the text into numerical features using techniques like bag-of-words, TF-IDF (Term Frequency-Inverse Document Frequency), or word embeddings to prepare it for machine learning models.<br>\n",
    "<b>5. Exploratory Data Analysis (EDA):</b> Understand the characteristics of the textual data through techniques such as frequency analysis, word clouds, and topic modeling to gain insights and identify patterns.<br>\n",
    "<b>6. Vectorization:</b> Converting textual data to numerical vectors.<br>\n",
    "<b>7. Modeling and Evaluation:</b> Apply machine learning or natural language processing models to the preprocessed textual data for tasks like sentiment analysis, text classification, or named entity recognition. Evaluate the model's performance using appropriate metrics.<br>\n",
    "<b>8. Iterative Refinement:</b> Refine the preprocessing and modeling steps based on the insights gained from the initial results, and iterate to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f5780",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3787eda",
   "metadata": {},
   "source": [
    "##### What are the steps in Data cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c8068",
   "metadata": {},
   "source": [
    "<b>Below are the steps that we should follow in Data Cleaning:</b><br>\n",
    "- lowercasing\n",
    "- removing leading and trailing spaces\n",
    "- removing html tags\n",
    "- removing urls\n",
    "- expanding abbreviations\n",
    "- spelling correction\n",
    "- punctuations\n",
    "- remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e03557",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ec29c",
   "metadata": {},
   "source": [
    "##### What are the steps in Data preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8babd",
   "metadata": {},
   "source": [
    "<b>Below are the steps that we should follow in Data preprocessing:</b><br>\n",
    "- tokenization\n",
    "- stopword removal\n",
    "- stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c97c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8fcde",
   "metadata": {},
   "source": [
    "##### What are the different techniques through which we can perform vectorization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25237a6f",
   "metadata": {},
   "source": [
    "<b>Below are the different options through which we can perform vectorization:</b><br>\n",
    "- <b>Bag-of-Words (BoW):</b> This technique represents text as a multiset of words, disregarding grammar and word order, and constructs a vocabulary of unique words in the corpus. Each document is then represented as a numerical vector indicating the presence or absence of words.\n",
    "- <b>Term Frequency-Inverse Document Frequency (TF-IDF):</b> TF-IDF measures the importance of a word in a document relative to a collection of documents. It assigns weights to words based on their frequency in the document and their rarity across the entire corpus.\n",
    "- <b>Word Embeddings:</b> Word embeddings, such as Word2Vec, GloVe, and FastText, represent words as dense vectors in a continuous vector space, capturing semantic and syntactic relationships between words.\n",
    "- <b>N-grams:</b> N-grams are contiguous sequences of n items (usually words) in the text. Vectorization using n-grams captures local word order information and can be used in conjunction with BoW or TF-IDF.\n",
    "- <b>Doc2Vec:</b> This technique extends the concept of Word2Vec to learn document-level embeddings, representing entire documents as continuous-valued vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c0da1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787be6f9",
   "metadata": {},
   "source": [
    "##### What are steps in Feature Engineering and EDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827ad98",
   "metadata": {},
   "source": [
    "- distribution of text length/word count\n",
    "- common unigrams/bigrams/trigrams\n",
    "- wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42975365",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864248d",
   "metadata": {},
   "source": [
    "##### What is ngrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f1d4d",
   "metadata": {},
   "source": [
    "N-grams are contiguous sequences of n items, typically used in the context of text, where the items are usually words. N-grams are used to capture the local word order and sequence of words in a document.\n",
    "For example, in the sentence \"The quick brown fox jumps over the lazy dog,\" some 2-grams (also known as bigrams) would be:\n",
    "- \"The quick\"\n",
    "- \"quick brown\"\n",
    "- \"brown fox\"\n",
    "- \"fox jumps\"\n",
    "- \"jumps over\"\n",
    "- \"over the\"\n",
    "- \"the lazy\"\n",
    "- \"lazy dog\"\n",
    "\n",
    "Similarly, 3-grams (trigrams) would be sequences of three words, and so on.\n",
    "N-grams are used in various natural language processing (NLP) tasks such as text analysis, language modeling, and feature extraction. They can capture contextual information and can be used in conjunction with techniques like bag-of-words or TF-IDF for text vectorization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ccfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
